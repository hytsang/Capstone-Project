mod$upper
fcast$upper
accuracy(fcast$upper,testing$visitsTumblr)
accuracy(fcast$lower,testing$visitsTumblr)
fcast$upper
fcast
testing$visitingTumblrs
testing$visitsTumblrs
testing$visitsTumblr
training$visitsTumblr
testing$visitsTumblr
accuracy(fcast,testing$visitsTumblr)
?accuracy
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
mod <- train(CompressiveStrength,data=training,method="svm")
names(training)
mod <- train(CompressiveStrength~.,data=training,method="svm")
?train
mod <- train(CompressiveStrength~.,data=training,method="svmLinear")
predict(mod,testing)
summary(predict(mod,testing))
confusionMatrix(predict(mod,testing),testing)
confusionMatrix(predict(mod,testing),testing$CompressiveStrength)
class(predict(mod,testing))
class(testing$CompressiveStrength)
testing$CompressiveStrength
confusionMatrix(predict(mod,testing),testing$CompressiveStrength)
length(predict(mod,testing))
length(testing$CompressiveStrength)
?RMSE
RMSE(predict(mod,testing),testing$CompressiveStrength)
RMSE(predict(mod,testing),testing$CompressiveStrength,na.rm=TRUE
)
RMSE(pred=predict(mod,testing),obs=testing$CompressiveStrength,na.rm=TRUE
)
mod <- train(CompressiveStrength~.,data=training,method="svmRadial")
RMSE(pred=predict(mod,testing),obs=testing$CompressiveStrength,na.rm=TRUE
)
library(lubridate)  # For year() function below
dat = read.csv("~/Desktop/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
library(lubridate)  # For year() function below
dat = read.csv("gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
mod <- bats(tstrain)
fcast <- forecast(mod)
fcast$upper
tstrain
testing
fcast$upper
predict(fcast,testing$visitsTumblr)
testing$visitsTumblr
row.names(predict(fcast,testing$visitsTumblr))
row.names(predict(fcast,testing$visitsTumblr))
row.names(predict(fcast,testing$visitsTumblr))
predict(fcast,testing$visitsTumblr)
slidify(index.rmd)
library(slidify)
slidify("index.rmd")
?sqldf
library(sqldf)
?sqldf
install.packages("RMySQL")
install.packages("tm")
source('~/Capstone Project/tokenizer.R')
library(e1071)
?svm
data(iris)
head(data)
head(iris)
summary(iris)
summary(iris)
model <- svm(Species~.,data=iris)
print(model)
summary(model)
predict(mode,iris)
predict(model,iris)
pred <- predict(mode,iris)
pred <- predict(model,iris)
table(pred,iris$species)
table(pred,iris$Species)
?naiveBayes
model <- naiveBayes(Species~.,data=iris)
print(model)
table(pred,iris$Species)
pred <- predict(model,iris)
table(pred,iris$Species)
?lm
?gl
?glm
glm(Species~.,data=iris)
iris$Species
glm(Species~.,data=iris)
head(iris)
str(iris)
?lm
data("galton")
install.packages("HistData")
data(galton)
library(Histdata)
library(HistData)
data("galton")
galton <- read.csv("http://blog.yhathq.com/static/misc/galton.csv",header=TRUE, stringsAsFactors=FALSE)
summary(galton)
fit <- lm(child~parent,data=galton)
fit
summary(fit)
plot(fit)
plot(fit)
plot(galton)
plot(model)
plot(model$fitted)
plot(galton$parent,model$fitted)
model$fitted
model$y
?lm
plot(galton$parent,model$fitted.values)
model$fitted.values
plot(galton$parent,fit$fitted.values)
line(galton$parent,fit$fitted.values)
?line
?lines
lines(galton$parent,fit$fitted.values)
plot(galton)
lines(galton$parent,fit$fitted.values)
lm(species~.,data=iris)
lm(Species~.,data=iris)
fit2 <- lm(Species~.,data=iris)
pred <- predict(fit2,iris)
table(pred,iris$Species)
table(pred,iris$Species)
summary(fit2)
fit2 <- lm(Species~.,data=iris)
head(iris)
summary(lm)
summary(fit2)
?lm
str(iris)
lm(Species~Sepal.Length + Sepal.Width + Petal.Width + Petal.Length,data=iris)
fit2 <- lm(Species~Sepal.Length + Sepal.Width + Petal.Width + Petal.Length,data=iris)
summary(fit2)
predict(fit2,iris)
load("~/Capstone Project/word_date2.RData")
predict <- function(str)
{
str <- stemDocument(VCorpus(VectorSource(str))[[1]])[[1]]
str <- removePunctuation(str)
str <- paste("<cs>",str)
str <- stripWhitespace(str)
str <- tolower(str)
vec <- unlist(strsplit(str," "))
len <- length(vec)
print(vec)
if (vec[len]%in%utf$term | vec[len]%in%btf$X1 | vec[len]%in%ttf$X2)
{
if (len>=3)
{
index <- which(qtf$X3==vec[len] & qtf$X2==vec[len-1] & qtf$X1==vec[len-2])
if (length(index)>0)
{
return(as.character(qtf[index[1],"X4"]))
}
}
if (len>=2)
{
index <- which(ttf$X2==vec[len] & ttf$X1==vec[len-1])
if (length(index)>0)
{
return(as.character(ttf[index[1],"X3"]))
}
}
index <- which(btf$X1==vec[len])
if (length(index)>0)
{
return(as.character(btf[index[1],"X2"]))
}
else predict(paste(vec[3:len],collapse=" "))
}
else predict(paste(vec[2:(len-1)],collapse=" "))
}
predict("i am")
library(T,)
library(tm)
library(T,)
predict("i am")
predict("id live and id")
predict("he started telling me about his")
predict("see arctic monkeys this")
predict("helps reduce your")
load("~/Capstone Project/probdata.RData")
predict <- function(str)
{
#str <- stemDocument(VCorpus(VectorSource(str))[[1]])[[1]]
#str <- removeWords(str,stopwords("english"))
str <- removePunctuation(str)
str <- paste("<cs>",str)
str <- stripWhitespace(str)
str <- tolower(str)
vec <- unlist(strsplit(str," "))
len <- length(vec)
print(vec)
if (vec[len]%in%utf$X1)
{
if (len>=3)
{
index <- which(qtf$X3==vec[len] & qtf$X2==vec[len-1] & qtf$X1==vec[len-2])
if (length(index)>0)
{
return(as.character(qtf$X4[index[1]]))
}
}
if (len>=2)
{
index <- which(ttf$X2==vec[len] & ttf$X1==vec[len-1])
if (length(index)>0)
{
return(as.character(ttf$X3[index[1]]))
}
}
index <- which(btf$X1==vec[len])
if (length(index)>0)
{
return(as.character(btf$X2[index[1]]))
}
}
return(utf$X1[1])
}
predict("")
library(tm)
predict("")
predict("the")
predict("the first")
predict("the first time")
predict("the first time in")
head(btf)
head(ttf)
predict <- function(str)
{
#str <- stemDocument(VCorpus(VectorSource(str))[[1]])[[1]]
#str <- removeWords(str,stopwords("english"))
str <- removePunctuation(str)
str <- stripWhitespace(str)
str <- tolower(str)
vec <- unlist(strsplit(str," "))
len <- length(vec)
print(vec)
if (vec[len]%in%utf$X1)
{
if (len>=3)
{
index <- which(qtf$X3==vec[len] & qtf$X2==vec[len-1] & qtf$X1==vec[len-2])
if (length(index)>0)
{
return(as.character(qtf$X4[index[1]]))
}
}
if (len>=2)
{
index <- which(ttf$X2==vec[len] & ttf$X1==vec[len-1])
if (length(index)>0)
{
return(as.character(ttf$X3[index[1]]))
}
}
index <- which(btf$X1==vec[len])
if (length(index)>0)
{
return(as.character(btf$X2[index[1]]))
}
}
return(utf$X1[1])
}
predict("")
str <- ""
str <- removePunctuation(str)
str <- stripWhitespace(str)
str <- tolower(str)
vec <- unlist(strsplit(str," "))
len <- length(vec)
print(vec)
predict <- function(str)
{
#str <- stemDocument(VCorpus(VectorSource(str))[[1]])[[1]]
#str <- removeWords(str,stopwords("english"))
str <- removePunctuation(str)
str <- stripWhitespace(str)
str <- tolower(str)
vec <- unlist(strsplit(str," "))
len <- length(vec)
print(vec)
if (len==0) return utf$X1[1]
if (vec[len]%in%utf$X1)
{
if (len>=3)
{
index <- which(qtf$X3==vec[len] & qtf$X2==vec[len-1] & qtf$X1==vec[len-2])
if (length(index)>0)
{
return(as.character(qtf$X4[index[1]]))
}
}
if (len>=2)
{
index <- which(ttf$X2==vec[len] & ttf$X1==vec[len-1])
if (length(index)>0)
{
return(as.character(ttf$X3[index[1]]))
}
}
index <- which(btf$X1==vec[len])
if (length(index)>0)
{
return(as.character(btf$X2[index[1]]))
}
}
return(utf$X1[1])
}
predict <- function(str)
{
#str <- stemDocument(VCorpus(VectorSource(str))[[1]])[[1]]
#str <- removeWords(str,stopwords("english"))
str <- removePunctuation(str)
str <- stripWhitespace(str)
str <- tolower(str)
vec <- unlist(strsplit(str," "))
len <- length(vec)
print(vec)
if (len==0)
{
return utf$X1[1]
}
if (vec[len]%in%utf$X1)
{
if (len>=3)
{
index <- which(qtf$X3==vec[len] & qtf$X2==vec[len-1] & qtf$X1==vec[len-2])
if (length(index)>0)
{
return(as.character(qtf$X4[index[1]]))
}
}
if (len>=2)
{
index <- which(ttf$X2==vec[len] & ttf$X1==vec[len-1])
if (length(index)>0)
{
return(as.character(ttf$X3[index[1]]))
}
}
index <- which(btf$X1==vec[len])
if (length(index)>0)
{
return(as.character(btf$X2[index[1]]))
}
}
return(utf$X1[1])
}
predict <- function(str)
{
#str <- stemDocument(VCorpus(VectorSource(str))[[1]])[[1]]
#str <- removeWords(str,stopwords("english"))
str <- removePunctuation(str)
str <- stripWhitespace(str)
str <- tolower(str)
vec <- unlist(strsplit(str," "))
len <- length(vec)
print(vec)
if (len==0)
{
return(utf$X1[1])
}
if (vec[len]%in%utf$X1)
{
if (len>=3)
{
index <- which(qtf$X3==vec[len] & qtf$X2==vec[len-1] & qtf$X1==vec[len-2])
if (length(index)>0)
{
return(as.character(qtf$X4[index[1]]))
}
}
if (len>=2)
{
index <- which(ttf$X2==vec[len] & ttf$X1==vec[len-1])
if (length(index)>0)
{
return(as.character(ttf$X3[index[1]]))
}
}
index <- which(btf$X1==vec[len])
if (length(index)>0)
{
return(as.character(btf$X2[index[1]]))
}
}
return(utf$X1[1])
}
predict("")
predict("the")
predict("the first")
predict("the first time")
predict("the first time in")
predict("the first time in the")
predict("the first time in the future")
predict("the first time in the future it")
predict("what is")
predict("what is the")
predict("what is the aptitude")
source('~/Cap Project/dsci-benchmark-master/benchmark.R')
setwd("~/Cap Project/dsci-benchmark-master")
source('~/Cap Project/dsci-benchmark-master/benchmark.R')
source('~/Cap Project/dsci-benchmark-master/benchmark.R')
setwd("~/Cap Project/dsci-benchmark-master")
source('~/Cap Project/dsci-benchmark-master/benchmark.R')
source('~/Cap Project/dsci-benchmark-master/benchmark.R')
source('~/Cap Project/dsci-benchmark-master/benchmark.R')
predict("what the")
predict("i am")
predict("i am not")
predict("i am not sure")
predict("i am not sure about")
predict("i am not sure about ip")
predict("what is")
predict("what is the")
predict("a")
predict("a lot")
predict("a lot of")
predict("a lot of people")
predict("a lot of people who")
predict("a lot of people who have")
predict("a lot of people who have a")
predict("a lot of people who have a coach")
predict("a lot of people who have a coach those")
predict("a lot of people who have a coach those who")
predict("a lot of people who have a coach those who need")
predict("a lot of people who have a coach those who need idea")
predict("a lot of people who have a coach those who need idea for")
predict("a lot of people who have a coach those who need idea for original")
head(utf)
which(utf$X1=="i")
head(utf,15)
rm(blogs)
rm(len)
rm(quizzes)
rm(str)
rm(totcount)
rm(tweets)
rm(vec)
rm(benchmark)
rm(bgramtokenizer)
rm(predict)
rm(predict.baseline)
rm(qgramtokenizer)
rm(sgramtokenizer)
rm(split.sentence)
rm(tgramtokenizer)
rm(toSpace)
save.image("~/Capstone Project/probdata.RData")
setwd("~/Capstone Project")
runApp()
library(shiny)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
vec <- "this the first"
strsplit(vec," ")
library(stringr)
word(vec)
word(vec)
word(vec,1)
word(vec,2)
word(vec,3)
word1 <- word(vec,1)
word2 <- word(vec,2)
word3 <- word(vec,3)
paste("[ ",word1," ]","[ ",word2," ]","[ ",word3," ]")
paste("[",word1,"]","[",word2,"]","[",word3,"]")
paste("[",word1,"]","[",word2,"]","[",word3,"]")
append(word1,word2,word3)
word <- word1
append(word,word2)
?print
?cat
cat(word1,word2,word3,sep="\n")
vec <- predict("who is")
?verbatimTextOutput
runApp()
runApp()
runApp()
runApp()
runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
