modFit <- train(classe~.,data=training,method="rf")
?nearZerovar
?nearZeroVar
nearZeroVar(training)
nearZeroVar(training,saveMetrics=TRUE)
nzv <- nearZeroVar(training,saveMetrics=TRUE)$nzv
training <- training[,-nzv]
head(nzv)
head(-nzv)
head(!nzv)
training <- training[,!nzv]
relevel(nzv,c(1,-1))
as.factor(nzv)
head(as.factor(nzv))
head(nzv)
head(relevel(as.factor(nzv),c(-1,1))
)
relevel
?relevel
nzv <- as.factor(nzv)
levels(nzv)
levels(nzv)[1] <- 1
levels(nzv)
levels(nzv)[1] <- -1
levels(nzv)[2] <- 1
levels(nzv)
nzv
training <- necessaryData[inTrain,nzv]
training <- necessaryData[inTrain,nzv]
testing <- necessaryData[-inTrain,nzv]
training <- necessaryData[inTrain,nzv]
training <- necessaryData[inTrain,]
testing <- necessaryData[-inTrain,]
nearZeroVar(training,saveMetrics=TRUE)$nzv
which(nearZeroVar(training,saveMetrics=TRUE)$nzv==TRUE)
training <- training[,-which(nearZeroVar(training,saveMetrics=TRUE)$nzv==TRUE)]
testing <- testing[,-which(nearZeroVar(training,saveMetrics=TRUE)$nzv==TRUE)]
modFit <- train(classe~.,data=training,method="gbm",verbose=FALSE)
confusionMatrix(testing$classe,predict(modFit,testing))
testing <- necessaryData[-inTrain,]
testing <- testing[,-which(nearZeroVar(training,saveMetrics=TRUE)$nzv==TRUE)]
training <- training[inTrain,-which(nearZeroVar(necessaryData,saveMetrics=TRUE)$nzv==TRUE)]
testing <- testing[-inTrain,-which(nearZeroVar(necessaryData,saveMetrics=TRUE)$nzv==TRUE)]
testing <- necessaryData[-inTrain,-which(nearZeroVar(necessaryData,saveMetrics=TRUE)$nzv==TRUE)]
training <- necessaryData[inTrain,-which(nearZeroVar(necessaryData,saveMetrics=TRUE)$nzv==TRUE)]
modFit <- train(classe~.,data=training,method="gbm",verbose=FALSE)
library(doMC)
registerDoMC(cores=2)
modFit$finalModel
confusionMatrix(testing$classe,predict(modFit,testing))
predict(modFit,testing)
length(predict(modFit,testing))
length(testing$classe)
testing$classe
predict(modFit,testing)
?predict
?predict.gbm
predict(modFit,training)
modFit
modFit$finalModel
predict(modFit,training)
length(predict(modFit,testing))
testing$classe[1:110]==predict(modFit,testing)
modFit <- train(classe~.,data=training,method="rpart",verbose=FALSE)
modFit <- train(classe~.,data=training,method="rpart")
predict(modFit,testing)
length(predict(modFit,testing))
dim(testing)
data <- read.csv("pml-training.csv")
names(data)
necessaryData <- data[,-c(1:5)]
nearZeroVar(necessaryData)
library(caret)
nearZeroVar(necessaryData)
necessaryData <- necessaryData[,-nearZeroVar(necessaryData)]
inTrain <- createDataPartition(necessaryData$classe,p=0.75,list=FALSE)
training <- necessaryData[inTrain,]
testing <- necessaryData[-inTrain,]
modFit <- train(classe~.,data=training,method="rpart")
predict(modFit,training)
predict(modFit,testing)
length(predict(modFit,testing))
length(predict(modFit,training))
modFit
?read.csv
predict(modFit,testing)
?predict
?predict.rpart
predict(modFit,testing,na.action=na.fail)
names(data)
predict(modFit,testing,type="class")
predict(modFit,testing,type="raw")
predict(modFit,testing,type="prob")
predict(modFit,testing)
complete.cases(training)
training <- training[complete.cases(training),]
install.packages("caret")
install.packages("caret")
install.packages("caret")
install.packages("caret")
data <- read.csv("pml-training.csv")
data <- read.csv(file = 'pml-training.csv',na.strings = c('NA','#DIV/0!',''))
is.na(data)
dim(is.na(data))
colSums(is.na(data))
colSums(is.na(data))==0
which(colSums(is.na(data))==0)
which(as.numeric(colSums(is.na(data)))==0)
cleanData <- which(as.numeric(colSums(is.na(data)))==0)
names(cleanDat)
names(cleanData)
cleanData <- data[,which(as.numeric(colSums(is.na(data)))==0)]
names(cleanData)
necessaryData <- cleandata[,-c(1:7)]
necessaryData <- cleanData[,-c(1:7)]
nearZeroVar(necessaryData)
library(caret)
nearZeroVar(necessaryData)
inTrain <- createDataPartition(necessaryData$classe,p=0.6,list=FALSE)
training <- necessaryData[inTrain,]
testing <- necessaryData[-inTrain,]
modFit <- train(classe~.,data=training,method="rpart")
predict(modFit,testing)
confusionMatrix(testing$classe,predict(modFit,testing))
?train
?trainControl
modFit <- train(classe~.,data=training,method="rf",trControl <- trainControl(method="cv",number=4,allowParallel=TRUE))
modFit <- train(classe~.,data=training,method="rf",trControl = trainControl(method="cv",number=4,allowParallel=TRUE,verboseIter=TRUE))
modFit <- train(classe~.,data=training,method="rf",trControl = trainControl(method="boot",allowParallel=TRUE,verboseIter=TRUE))
sapply(data,function(x) sum(is.na(x)))
table(sapply(data,function(x) sum(is.na(x))))
data <- read.csv("pml-training.csv",na.string=c("","NA","NULL"))
table(sapply(data,function(x) sum(is.na(x))))
cleanData <- data[,which(as.numeric(colSums(is.na(data)))==0)]
nearZeroVar(cleanData)
cleanData <- cleanData[,-c(1:7)] #First 7 Columns Of The dataset are removed
nearZeroVar(cleanData)
findCorrelation(cleanData)
?findCorrelation
modFit <- train(classe~.,data=training,method="gbm",verbose=FALSE)
modFit <- train(classe~.,data=training,method="rpart",verbose=FALSE)
modFit <- train(classe~.,data=training,method="rpart")
modFit <- train(classe~.,data=training,method="rpart",trControl = trainControl(method="cv",number=4,allowParallel=TRUE))
confusionMatrix(testing$classe,predict(modFit,testing))
cleanData <- data[,which(as.numeric(colSums(is.na(data)))==0)]
cleanData <- cleanData[,-c(1:7)] #First 7 Columns Of The dataset are removed
inTrain <- createDataPartition(cleanData$classe,p=0.7,list=FALSE)
training <- cleanData[inTrain,]
testing <- cleanData[-inTrain,]
modFit <- train(classe~.,data=training,method="rpart",trControl = trainControl(method="cv",number=4,allowParallel=TRUE))
confusionMatrix(testing$classe,predict(modFit,testing))
any(is.na(training))
any(is.na(testing))
modFit <- train(classe~.,data=training,method="rf",trControl = trainControl(method="cv",number=4,allowParallel=TRUE))
modFit <- train(classe~.,data=training,method="rf",trControl = trainControl(method="cv",number=4,allowParallel=TRUE,verboseIter=TRUE))
library(doMC)
registerDoMC(cores=2)
modFit <- train(classe~.,data=training,method="rf",trControl = trainControl(method="cv",number=4,allowParallel=TRUE,verboseIter=TRUE))
?train
library(caret)
?train
?trainControl
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
names(vowel.train)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
mod1 <- train(y~.,data=vowel.train,method="rf")
library(caret)
mod1 <- train(y~.,data=vowel.train,method="rf")
mod2 <- train(y~.,data=vowel.train,method="gbm")
mod2
mode2$finalModel
mod2$finalModel
summary(mod2$finalModel)
predict(mod1,vowel.test)
confusionMatrix(predict(mod1,vowel.test),vowel.test$y)
confusionMatrix(predict(mod2,vowel.test),vowel.test$y)
confusionMatrix(predict(mod1,vowel.test),vowel.test$y)
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
mod1 <- train(diagnosis~.,data=training,method="rf")
mod2 <- train(diagnosis~.,data=training,method="gbm")
mod3 <- train(diagnosis~.,data=training,method="lda")
pred1 <- predict(mod1,testing)
pred2 <- predict(mod2,testing)
pred3 <- predict(mod3,testing)
preds <- as.data.frame(pred1,pred2,pred3,testing$diagnosis)
testing$diagnosis
pred1
pred2
pred3
data.frame(pred1,pred2,pred3,testing$diagnosis)
predDF <- data.frame(pred1,pred2,pred3,testing$diagnosis)
combMod <- train(diagnosis~.,data=predDF,method="rf")
names(predDF)
combMod <- train(testing.diagnosis~.,data=predDF,method="rf")
predict(combMod,testing)
predict(combMod,predDF)
confusionMatrix(predict(combMod,predDF),prefDF$testing.diagnosis)
confusionMatrix(predict(combMod,predDF),predDF$testing.diagnosis)
confusionMatrix(pred1,testing$diagnosis)
confusionMatrix(pred2,testing$diagnosis)
confusionMatrix(pred3,testing$diagnosis)
ibrary(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(32433)
set.seed(62433)
pred1 <- train(diagnosis~.,data=training,method="rf")
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(@33)
set.seed(233)
mod <- train(CompressiveStrength~.,data=training,method="lasso")
mod <- train(CompressiveStrength~.,data=training,method="lasso")
plot(mod)
plot(mod$finalModel)
plot.enet
?plot.enet
class(mod$finalModel)
plot(mod$finalModel)
names(training)
mod$finalModel
qplot(mod$finalModel)
library(lubridate)  # For year() function below
dat = read.csv("gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
install.packages("lubridate")
library(lubridate)  # For year() function below
dat = read.csv("gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
tstrain
plot(tstrain)
qplot(tstrain)
plot(tstrain)
?bats
library(forecast)
install.packages(forecast)
install.packages("forecast")
?bats
library(forecast)
?bats
names(tstrain)
bats(tstrain)
mod <- bats(tstrain)
fcast <- forecast(mod)
plot(fcast)
accuracy(fcast,testing)
accuracy(fcast,ts(testing$visitsTumblr))
mod
tstest <- ts(testing$visitsTumblr)
accuracy(fcast,tstest)
plot(fcast)
plot(tstrain)
plot(tstest)
library(lubridate)  # For year() function below
dat = read.csv("~/Desktop/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
library(lubridate)  # For year() function below
dat = read.csv("gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
tstest = ts(testing$visitsTumblr)
mod <- bats(tstrain)
forecast(mod)
fcast <- forecast(mod)
accuracy(fcast,tstest)
accuracy(fcast,testing$visitsTumblr)
bats$upper
mode$upper
mod$upper
fcast$upper
accuracy(fcast$upper,testing$visitsTumblr)
accuracy(fcast$lower,testing$visitsTumblr)
fcast$upper
fcast
testing$visitingTumblrs
testing$visitsTumblrs
testing$visitsTumblr
training$visitsTumblr
testing$visitsTumblr
accuracy(fcast,testing$visitsTumblr)
?accuracy
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
mod <- train(CompressiveStrength,data=training,method="svm")
names(training)
mod <- train(CompressiveStrength~.,data=training,method="svm")
?train
mod <- train(CompressiveStrength~.,data=training,method="svmLinear")
predict(mod,testing)
summary(predict(mod,testing))
confusionMatrix(predict(mod,testing),testing)
confusionMatrix(predict(mod,testing),testing$CompressiveStrength)
class(predict(mod,testing))
class(testing$CompressiveStrength)
testing$CompressiveStrength
confusionMatrix(predict(mod,testing),testing$CompressiveStrength)
length(predict(mod,testing))
length(testing$CompressiveStrength)
?RMSE
RMSE(predict(mod,testing),testing$CompressiveStrength)
RMSE(predict(mod,testing),testing$CompressiveStrength,na.rm=TRUE
)
RMSE(pred=predict(mod,testing),obs=testing$CompressiveStrength,na.rm=TRUE
)
mod <- train(CompressiveStrength~.,data=training,method="svmRadial")
RMSE(pred=predict(mod,testing),obs=testing$CompressiveStrength,na.rm=TRUE
)
library(lubridate)  # For year() function below
dat = read.csv("~/Desktop/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
library(lubridate)  # For year() function below
dat = read.csv("gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
mod <- bats(tstrain)
fcast <- forecast(mod)
fcast$upper
tstrain
testing
fcast$upper
predict(fcast,testing$visitsTumblr)
testing$visitsTumblr
row.names(predict(fcast,testing$visitsTumblr))
row.names(predict(fcast,testing$visitsTumblr))
row.names(predict(fcast,testing$visitsTumblr))
predict(fcast,testing$visitsTumblr)
slidify(index.rmd)
library(slidify)
slidify("index.rmd")
?sqldf
library(sqldf)
?sqldf
install.packages("RMySQL")
install.packages("tm")
source('~/Capstone Project/tokenizer.R')
library(e1071)
?svm
data(iris)
head(data)
head(iris)
summary(iris)
summary(iris)
model <- svm(Species~.,data=iris)
print(model)
summary(model)
predict(mode,iris)
predict(model,iris)
pred <- predict(mode,iris)
pred <- predict(model,iris)
table(pred,iris$species)
table(pred,iris$Species)
?naiveBayes
model <- naiveBayes(Species~.,data=iris)
print(model)
table(pred,iris$Species)
pred <- predict(model,iris)
table(pred,iris$Species)
?lm
?gl
?glm
glm(Species~.,data=iris)
iris$Species
glm(Species~.,data=iris)
head(iris)
str(iris)
?lm
data("galton")
install.packages("HistData")
data(galton)
library(Histdata)
library(HistData)
data("galton")
galton <- read.csv("http://blog.yhathq.com/static/misc/galton.csv",header=TRUE, stringsAsFactors=FALSE)
summary(galton)
fit <- lm(child~parent,data=galton)
fit
summary(fit)
plot(fit)
plot(fit)
plot(galton)
plot(model)
plot(model$fitted)
plot(galton$parent,model$fitted)
model$fitted
model$y
?lm
plot(galton$parent,model$fitted.values)
model$fitted.values
plot(galton$parent,fit$fitted.values)
line(galton$parent,fit$fitted.values)
?line
?lines
lines(galton$parent,fit$fitted.values)
plot(galton)
lines(galton$parent,fit$fitted.values)
lm(species~.,data=iris)
lm(Species~.,data=iris)
fit2 <- lm(Species~.,data=iris)
pred <- predict(fit2,iris)
table(pred,iris$Species)
table(pred,iris$Species)
summary(fit2)
fit2 <- lm(Species~.,data=iris)
head(iris)
summary(lm)
summary(fit2)
?lm
str(iris)
lm(Species~Sepal.Length + Sepal.Width + Petal.Width + Petal.Length,data=iris)
fit2 <- lm(Species~Sepal.Length + Sepal.Width + Petal.Width + Petal.Length,data=iris)
summary(fit2)
predict(fit2,iris)
load("~/Capstone Project/word_date2.RData")
predict <- function(str)
{
str <- stemDocument(VCorpus(VectorSource(str))[[1]])[[1]]
str <- removePunctuation(str)
str <- paste("<cs>",str)
str <- stripWhitespace(str)
str <- tolower(str)
vec <- unlist(strsplit(str," "))
len <- length(vec)
print(vec)
if (vec[len]%in%utf$term | vec[len]%in%btf$X1 | vec[len]%in%ttf$X2)
{
if (len>=3)
{
index <- which(qtf$X3==vec[len] & qtf$X2==vec[len-1] & qtf$X1==vec[len-2])
if (length(index)>0)
{
return(as.character(qtf[index[1],"X4"]))
}
}
if (len>=2)
{
index <- which(ttf$X2==vec[len] & ttf$X1==vec[len-1])
if (length(index)>0)
{
return(as.character(ttf[index[1],"X3"]))
}
}
index <- which(btf$X1==vec[len])
if (length(index)>0)
{
return(as.character(btf[index[1],"X2"]))
}
else predict(paste(vec[3:len],collapse=" "))
}
else predict(paste(vec[2:(len-1)],collapse=" "))
}
predict("i am")
library(T,)
library(tm)
library(T,)
predict("i am")
predict("id live and id")
predict("he started telling me about his")
predict("see arctic monkeys this")
predict("helps reduce your")
install.packages("grid")
library(grid)
setwd("~/Capstone Project")
img <- readPNG("img.png")
library(png)
img <- readPNG("img.png")
grid.raster(img)
runApp()
library(shiny)
runApp()
runApp()
deployApp()
library(shinyapps)
deployApp()
deployApp()
